{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of New CSV with Languages & no Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U git+https://github.com/aboSamoor/polyglot.git@master\n",
    "# create track language column, done\n",
    "# df = pd.read_csv('https://raw.githubusercontent.com/aguilargallardo/DS-Unit-2-Applied-Modeling/master/data/SpotifyFeatures.csv')\n",
    "# df = df.dropna()\n",
    "# df = df.drop_duplicates(subset=['track_name', 'artist_name'])\n",
    "# raw_df = raw_df.drop_duplicates(subset='track_name')\n",
    "# raw_df.shape\n",
    "# raw_df.to_csv('spotify_unique_track_id.csv', index=False)\n",
    "# df.shape\n",
    "\n",
    "# df.to_csv('spotify_unique_track_id.csv', index=False)\n",
    "# Data already has duplicate track names and nulls removed.\n",
    "# from polyglot.text import Text,Word\n",
    "# def get_language(track_name):\n",
    "#     try:\n",
    "#         return(Text(track_name).language.name)\n",
    "#     except: \n",
    "#         return(\"Unknown\")\n",
    "\n",
    "# df.track_name = df.track_name.astype(str)\n",
    "# df['track_lang'] = df.track_name.apply(get_language)\n",
    "\n",
    "# df.to_csv('spotify_unique_track_id_lang.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kgdLqZi5sa4A"
   },
   "source": [
    "# Imports and Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2BCdkR4U5SR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "#import pandas_profiling \n",
    "from sklearn import preprocessing # for category encoder\n",
    "# from polyglot.detect import Detector # for language detection stretch\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "# much more efficient for larger files like Nearest Neighbors which the model\n",
    "import joblib\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RA1kLoqhsemw"
   },
   "source": [
    "# EDA & PROFILE REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232725, 19)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/Build-Week-Spotify-Song-Suggester-5/Data-Science/master/spotify_unique_track_id_lang.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-order track_lang from the end to after track_name\n",
    "df = df [['genre', 'artist_name', 'track_name', 'track_lang', 'track_id', 'popularity',\n",
    "       'acousticness', 'danceability', 'duration_ms', 'energy',\n",
    "       'instrumentalness', 'key', 'liveness', 'loudness', 'mode',\n",
    "       'speechiness', 'tempo', 'time_signature', 'valence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 19)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# they can only fit 75k on the Heroku\n",
    "df = df.sort_values('popularity', ascending=False)[:75000]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Stretch Goal Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install plotly\n",
    "# def create_web_chart(df):\n",
    "#     music_features = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'speechiness', 'valence']\n",
    "    \n",
    "#     fig = go.Figure()\n",
    "\n",
    "#     for idx, row in df.iterrows():\n",
    "#         # vals = list(df.iloc[idx][music_features].values)\n",
    "#         row_df = pd.DataFrame(df.loc[idx][music_features].T).reset_index().rename(columns={idx:'values', 'index':'feature'})\n",
    "#         fig.add_trace(go.Scatterpolar(\n",
    "#                                     r=row_df['values'],\n",
    "#                                     theta=row_df['feature'],\n",
    "#                                     fill='toself',\n",
    "#                                     name= f'{row.artist_name} - {row.track_name}'\n",
    "#                     ))\n",
    "#     # fig.show()\n",
    "#     return fig\n",
    "# fig = create_web_chart(df.iloc[0:5])\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "# first_song_values = list(df.iloc[0][music_features].values)\n",
    "# second_song_values = list(df.iloc[1][music_features].values)\n",
    "# fig = px.bar(first_song_df, x='feature', y=\"values\", color='feature')\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "\n",
    "# fig.add_trace(go.Scatterpolar(\n",
    "#       r=second_song_df['values'],\n",
    "#       theta=second_song_df['feature'],\n",
    "#       fill='toself',\n",
    "#       name='Second Song'\n",
    "# ))\n",
    "\n",
    "# fig.update_layout(\n",
    "#   polar=dict(\n",
    "#     radialaxis=dict(\n",
    "#       visible=True,\n",
    "#       range=[0, 1]\n",
    "#     )),\n",
    "#   showlegend=True\n",
    "# )\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENCODING OF FEATURES\n",
    "\n",
    "NOTE THAT IF YOU RUN THIS CELL AGAIN WITHOUT RESTARTING RUNTIME YOU'LL ENCODE AND BIND ANOTHER COPY OF GENRE ENCODINGS SIGNIFICANTLY INCREASING THE SIZE OF THE FEATURE SET WHILE ADDING NEGATIVE VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ye5e46vbZdHJ"
   },
   "outputs": [],
   "source": [
    "# helper function to one hot encode genre\n",
    "def encode_and_bind(original_dataframe, feature_to_encode):\n",
    "    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n",
    "    res = pd.concat([original_dataframe, dummies], axis=1)\n",
    "    return(res)\n",
    "\n",
    "time_sig_encoding = { '0/4' : 0, '1/4' : 1, \n",
    "                         '3/4' : 3, '4/4' : 4,\n",
    "                         '5/4' : 5}\n",
    "\n",
    "key_encoding = { 'A' : 0, 'A#' : 1, 'B' : 2,\n",
    "                    'C' : 3,  'C#' : 4,  'D' : 5,\n",
    "                    'D#' : 6, 'E' : 7, 'F' : 8,\n",
    "                    'F#' : 9, 'G' : 10, 'G#' : 11 }\n",
    "\n",
    "mode_encoding = { 'Major':0, 'Minor':1}      \n",
    "\n",
    "df['key'] = df['key'].map(key_encoding)\n",
    "df['time_signature'] = df['time_signature'].map(time_sig_encoding)\n",
    "df['mode'] = df['mode'].map(mode_encoding)\n",
    "df = encode_and_bind(df, 'genre')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = encode_and_bind(df, 'track_lang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_lang</th>\n",
       "      <th>track_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>track_lang_Waray</th>\n",
       "      <th>track_lang_Welsh</th>\n",
       "      <th>track_lang_Western Frisian</th>\n",
       "      <th>track_lang_Wolof</th>\n",
       "      <th>track_lang_Xhosa</th>\n",
       "      <th>track_lang_Yoruba</th>\n",
       "      <th>track_lang_Zhuang</th>\n",
       "      <th>track_lang_Zulu</th>\n",
       "      <th>track_lang_un</th>\n",
       "      <th>track_lang_zzp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9027</th>\n",
       "      <td>Dance</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>7 rings</td>\n",
       "      <td>English</td>\n",
       "      <td>14msK75pk3pA33pzPVNtBF</td>\n",
       "      <td>100</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.725</td>\n",
       "      <td>178640</td>\n",
       "      <td>0.321</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107804</th>\n",
       "      <td>Pop</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>7 rings</td>\n",
       "      <td>English</td>\n",
       "      <td>14msK75pk3pA33pzPVNtBF</td>\n",
       "      <td>100</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.725</td>\n",
       "      <td>178640</td>\n",
       "      <td>0.321</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        genre    artist_name track_name track_lang                track_id  \\\n",
       "9027    Dance  Ariana Grande    7 rings    English  14msK75pk3pA33pzPVNtBF   \n",
       "107804    Pop  Ariana Grande    7 rings    English  14msK75pk3pA33pzPVNtBF   \n",
       "\n",
       "        popularity  acousticness  danceability  duration_ms  energy  ...  \\\n",
       "9027           100         0.578         0.725       178640   0.321  ...   \n",
       "107804         100         0.578         0.725       178640   0.321  ...   \n",
       "\n",
       "        track_lang_Waray  track_lang_Welsh  track_lang_Western Frisian  \\\n",
       "9027                   0                 0                           0   \n",
       "107804                 0                 0                           0   \n",
       "\n",
       "        track_lang_Wolof  track_lang_Xhosa  track_lang_Yoruba  \\\n",
       "9027                   0                 0                  0   \n",
       "107804                 0                 0                  0   \n",
       "\n",
       "        track_lang_Zhuang  track_lang_Zulu  track_lang_un  track_lang_zzp  \n",
       "9027                    0                0              0               0  \n",
       "107804                  0                0              0               0  \n",
       "\n",
       "[2 rows x 160 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.genre.value_counts()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['genre', 'artist_name', 'track_name', 'track_lang', 'track_id',\n",
       "       'popularity', 'acousticness', 'danceability', 'duration_ms', 'energy',\n",
       "       ...\n",
       "       'track_lang_Waray', 'track_lang_Welsh', 'track_lang_Western Frisian',\n",
       "       'track_lang_Wolof', 'track_lang_Xhosa', 'track_lang_Yoruba',\n",
       "       'track_lang_Zhuang', 'track_lang_Zulu', 'track_lang_un',\n",
       "       'track_lang_zzp'],\n",
       "      dtype='object', length=160)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zw-EHBcot9td"
   },
   "source": [
    "# MODELING: Nearest Neighbors\n",
    "resources: https://scikit-learn.org/stable/modules/neighbors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hGlvDu8lQfRf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=25, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model\n",
    "neigh = NearestNeighbors(n_neighbors=25)\n",
    "not_features = ['genre', 'artist_name', 'track_name', 'track_lang', 'track_id'] # in case someone wants to change it later\n",
    "features =[item for item in list(df.columns) if item not in not_features]\n",
    "X = df[features].values\n",
    "# y = df[target]\n",
    "# X.shape \n",
    "# y.shape\n",
    "# target = 'track_id'\n",
    "\n",
    "%time\n",
    "neigh.fit(X) # NN doesn't need to fit Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Model Test on 1 Song Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXgOux8Y1eFF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist: Clare Dunn - Track: Put You Into Words\n",
      "Artist: Souly Had - Track: Speaking Of\n",
      "Artist: Souly Had - Track: Speaking Of\n",
      "Artist: Chris Brown - Track: High End\n",
      "Artist: Chris Brown - Track: High End\n",
      "Artist: Chris Brown - Track: High End\n",
      "Artist: Feid - Track: Sígueme\n",
      "Artist: Why Don't We - Track: Invitation\n",
      "Artist: Why Don't We - Track: Invitation\n",
      "Artist: Dread Mar I - Track: De Qué Me Vas a Hablar\n",
      "Artist: NAV - Track: EAT (feat. Gunna)\n",
      "Artist: NAV - Track: EAT (feat. Gunna)\n",
      "Artist: The Main Ingredient - Track: Everybody Plays the Fool\n",
      "Artist: The Main Ingredient - Track: Everybody Plays the Fool\n",
      "Artist: Easy Life - Track: Temporary Love Part 1\n",
      "Artist: Sticky Fingers - Track: How To Fly\n",
      "Artist: Sticky Fingers - Track: How To Fly\n",
      "Artist: Rush - Track: Fly By Night\n",
      "Artist: Big K.R.I.T. - Track: Prove It (feat. J. Cole)\n",
      "Artist: The Rolling Stones - Track: Paint It, Black\n",
      "Artist: Sigala - Track: Sweet Lovin' - Radio Edit\n",
      "Artist: One Direction - Track: I Would\n",
      "Artist: One Direction - Track: I Would\n",
      "[('Clare Dunn', 'Put You Into Words'), ('Souly Had', 'Speaking Of'), ('Souly Had', 'Speaking Of'), ('Chris Brown', 'High End'), ('Chris Brown', 'High End'), ('Chris Brown', 'High End'), ('Feid', 'Sígueme'), (\"Why Don't We\", 'Invitation'), (\"Why Don't We\", 'Invitation'), ('Dread Mar I', 'De Qué Me Vas a Hablar'), ('NAV', 'EAT (feat. Gunna)'), ('NAV', 'EAT (feat. Gunna)'), ('The Main Ingredient', 'Everybody Plays the Fool'), ('The Main Ingredient', 'Everybody Plays the Fool'), ('Easy Life', 'Temporary Love Part 1'), ('Sticky Fingers', 'How To Fly'), ('Sticky Fingers', 'How To Fly'), ('Rush', 'Fly By Night'), ('Big K.R.I.T.', 'Prove It (feat. J. Cole)'), ('The Rolling Stones', 'Paint It, Black'), ('Sigala', \"Sweet Lovin' - Radio Edit\"), ('One Direction', 'I Would'), ('One Direction', 'I Would')]\n"
     ]
    }
   ],
   "source": [
    "# random test song\n",
    "\n",
    "test_song = X[8980]\n",
    "df.iloc[8980]\n",
    "\n",
    "distance, neighbors = neigh.kneighbors(np.array([test_song]))\n",
    "distance, neighbors\n",
    "\n",
    "song_list = []\n",
    "for idx in neighbors[0][2:]: # this way excludes itself\n",
    "    row = df.iloc[idx]\n",
    "    print(f'Artist: {row.artist_name} - Track: {row.track_name}')\n",
    "    song_list.append((row.artist_name, row.track_name))\n",
    "print(song_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Function to Return 10 Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function for what was done manually above\n",
    "generalized for other dataframes instead of hard coded therefore:\n",
    "takes in a dataframe, a feature set array, and a song ID\n",
    "and returns a list of song_id\n",
    "\"\"\"\n",
    "from typing import List, Tuple\n",
    "import random \n",
    "\n",
    "def closest_ten(df: pd.DataFrame, X_array: np.ndarray ,song_id: int) -> List[Tuple] :\n",
    "    song = df.iloc[song_id]\n",
    "    X_song = X[song_id]\n",
    "    _, neighbors = neigh.kneighbors(np.array([X_song]))\n",
    "    song_list = []\n",
    "    for idx in neighbors[0][2:]: \n",
    "        row = df.iloc[idx]\n",
    "       # print(f'Artist: {row.artist_name} - Track: {row.track_name}')\n",
    "        song_list.append(row.track_id)\n",
    "    only_10 = random.sample(song_list, 10)\n",
    "    return(only_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NXi-FUX6sbWm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0c99BUd87HQfzgUUQqRyds',\n",
       " '4E8u5JsVnF3qPXbNiR9m25',\n",
       " '1depKpsqGCvr8wtjFFaFoO',\n",
       " '4E8u5JsVnF3qPXbNiR9m25',\n",
       " '3T5mo7mlf8vtRrtEPpOFmY',\n",
       " '6B4jeM3B33v2dE709U4dS2',\n",
       " '4l5lF04xjhTfYSopCXc4FU',\n",
       " '2TXzXJWWzESQq5glbDtZc9',\n",
       " '7bhSQqbyUvFVfmXgkF028O',\n",
       " '6B4jeM3B33v2dE709U4dS2']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of function call \n",
    "closest_ten(df, X, 9027)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA -> NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy to transform in case you want to do stuff with the other one later in notebook\n",
    "df_copy = df[features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array, mean, std, cov\n",
    "from numpy.linalg import eig\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = df_copy.mean()\n",
    "# print(\"\\n Means:\", means)\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_X = scaler.fit_transform(df_copy.values)\n",
    "pca = PCA(0.95)\n",
    "df_pca = pca.fit(pca_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.45794341 2.6619331  1.73667879 1.51142396 1.37838907 1.2611412\n",
      " 1.13150022 1.10768792 1.07033582 1.06444661 1.06026414 1.05531529\n",
      " 1.05322221 1.05195636 1.0498224  1.04842724 1.04708279 1.04401482\n",
      " 1.03562486 1.02767329 1.02411178 1.01842098 1.01476388 1.01108687\n",
      " 1.00834383 1.00137027 0.98850912 0.92596955 0.82414355 0.79806926\n",
      " 0.75307744 0.56700277 0.51077434]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=50, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "pca_neigh = NearestNeighbors(n_neighbors=50)\n",
    "pca_neigh.fit(pca_X) # NN doesn't need to fit Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refactor later if have time\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# pipeline = make_pipeline(\n",
    "#     StandardScaler(),\n",
    "#     NearestNeighbors())\n",
    "\n",
    "# pipeline.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Encoder -> NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 10 # compression of factor 4.1 assuming input of 41"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "38aCXICFoz55"
   },
   "source": [
    "# Export Model with Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4SBVgLGvn8hS"
   },
   "outputs": [],
   "source": [
    "filename = 'NearestNeighborGenres.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kLfmVJiKoN8X"
   },
   "outputs": [],
   "source": [
    "joblib.dump(neigh, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_filename = 'PCANearestNeighborGenres.sav'\n",
    "joblib.dump(pca_neigh, pca_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VD4hvXIVwyRG"
   },
   "outputs": [],
   "source": [
    "# one hot encoding, rolled back\n",
    "# def encode_and_bind(original_dataframe, feature_to_encode):\n",
    "#     dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n",
    "#     res = pd.concat([original_dataframe, dummies], axis=1)\n",
    "#     return(res)\n",
    "\n",
    "# df = encode_and_bind(df, 'key')\n",
    "# df = encode_and_bind(df, 'mode')\n",
    "# df = encode_and_bind(df, 'time_signature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Model with Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d0G2dBalpjTx"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model = neigh\n",
    "\n",
    "filename = 'filename.pkl'\n",
    "\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "#then send this pkl file to DE team\n",
    "\n",
    "#DE team:\n",
    "#Make sure to save the pkl file in the same folder as the app\n",
    "\n",
    "#To read it into the app:\n",
    "\n",
    "# with open(filename, 'rb') as f:\n",
    "#     model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Spotify_Model.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "U4-S2-NN",
   "language": "python",
   "name": "u4-s2-nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
