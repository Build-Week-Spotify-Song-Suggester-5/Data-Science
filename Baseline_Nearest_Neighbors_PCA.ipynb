{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kgdLqZi5sa4A"
   },
   "source": [
    "# Imports and Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IzCZwfItsOVX"
   },
   "outputs": [],
   "source": [
    "# install latest version of polyglot language detection library for stretch\n",
    "# !pip install -U git+https://github.com/aboSamoor/polyglot.git@master\n",
    "\n",
    "# !pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2BCdkR4U5SR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "#import pandas_profiling \n",
    "from sklearn import preprocessing # for category encoder\n",
    "# from polyglot.detect import Detector # for language detection stretch\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "# much more efficient for larger files like Nearest Neighbors which the model\n",
    "import joblib\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RA1kLoqhsemw"
   },
   "source": [
    "# EDA & PROFILE REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "raw_df = pd.read_csv('https://raw.githubusercontent.com/aguilargallardo/DS-Unit-2-Applied-Modeling/master/data/SpotifyFeatures.csv')\n",
    "raw_df = raw_df.dropna() # drop null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232725, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Movie</td>\n",
       "      <td>Henri Salvador</td>\n",
       "      <td>C'est beau de faire un Show</td>\n",
       "      <td>0BRjO6ga9RKCKjfDqeFgWV</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.389</td>\n",
       "      <td>99373</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C#</td>\n",
       "      <td>0.346</td>\n",
       "      <td>-1.828</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>166.969</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genre     artist_name                   track_name                track_id  \\\n",
       "0  Movie  Henri Salvador  C'est beau de faire un Show  0BRjO6ga9RKCKjfDqeFgWV   \n",
       "\n",
       "   popularity  acousticness  danceability  duration_ms  energy  \\\n",
       "0           0         0.611         0.389        99373    0.91   \n",
       "\n",
       "   instrumentalness key  liveness  loudness   mode  speechiness    tempo  \\\n",
       "0               0.0  C#     0.346    -1.828  Major       0.0525  166.969   \n",
       "\n",
       "  time_signature  valence  \n",
       "0            4/4    0.814  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = raw_df.drop_duplicates(subset='track_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148615, 18)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.to_csv('spotify_unique_track_id.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_web_chart(df):\n",
    "#     music_features = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'speechiness', 'valence']\n",
    "    \n",
    "#     fig = go.Figure()\n",
    "\n",
    "#     for idx, row in df.iterrows():\n",
    "#         # vals = list(df.iloc[idx][music_features].values)\n",
    "#         row_df = pd.DataFrame(df.loc[idx][music_features].T).reset_index().rename(columns={idx:'values', 'index':'feature'})\n",
    "#         fig.add_trace(go.Scatterpolar(\n",
    "#                                     r=row_df['values'],\n",
    "#                                     theta=row_df['feature'],\n",
    "#                                     fill='toself',\n",
    "#                                     name= f'{row.artist_name} - {row.track_name}'\n",
    "#                     ))\n",
    "#     # fig.show()\n",
    "#     return fig\n",
    "\n",
    "# fig = create_web_chart(df.iloc[0:5])\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_song_values = list(df.iloc[0][music_features].values)\n",
    "# second_song_values = list(df.iloc[1][music_features].values)\n",
    "\n",
    "# fig = px.bar(first_song_df, x='feature', y=\"values\", color='feature')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.add_trace(go.Scatterpolar(\n",
    "#       r=second_song_df['values'],\n",
    "#       theta=second_song_df['feature'],\n",
    "#       fill='toself',\n",
    "#       name='Second Song'\n",
    "# ))\n",
    "\n",
    "# fig.update_layout(\n",
    "#   polar=dict(\n",
    "#     radialaxis=dict(\n",
    "#       visible=True,\n",
    "#       range=[0, 1]\n",
    "#     )),\n",
    "#   showlegend=True\n",
    "# )\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l3YOD4aFtUfj"
   },
   "source": [
    "# DATA ENGINEERING CATEGORY ENCODING OF OBJECT FEATURES\n",
    "note: might need to create another column of encoded languages\n",
    "resources below: https://chrisalbon.com/machine_learning/preprocessing_structured_data/convert_pandas_categorical_column_into_integers_for_scikit-learn/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZPBCYrRgj0GC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n   TODO: figure out UTF-8 ERROR or just do try catch exception and return \\n   unknown or something\\n   below code does not work\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # test of polyglot detector\n",
    "\n",
    "# arabic_text = u\"\"\"\n",
    "# أفاد مصدر امني في قيادة عمليات صلاح الدين في العراق بأن \" القوات الامنية تتوقف لليوم\n",
    "# الثالث على التوالي عن التقدم الى داخل مدينة تكريت بسبب\n",
    "# انتشار قناصي التنظيم الذي يطلق على نفسه اسم \"الدولة الاسلامية\" والعبوات الناسفة\n",
    "# والمنازل المفخخة والانتحاريين، فضلا عن ان القوات الامنية تنتظر وصول تعزيزات اضافية \".\n",
    "# \"\"\"\n",
    "\n",
    "# detector = Detector(arabic_text)\n",
    "# print(detector.language)\n",
    "\n",
    "\n",
    "#    TODO: figure out UTF-8 ERROR or just do try catch exception and return \n",
    "#    unknown or something\n",
    "#    below code does not work\n",
    "\n",
    "\n",
    "# df.track_name = df.track_name.astype(str)\n",
    "# df['poly_obj'] = df.track_name.apply(lambda x: Detector(x, quiet=True))\n",
    "# df['Track-lang'] = df['poly_obj'].apply(lambda x: icu.Locale.getDisplayName(x.language.locale))\n",
    "# df['Track-LangConfidence'] = df['poly_obj'].apply( lambda x: x.language.confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ye5e46vbZdHJ"
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'df' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-7921fa2015e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencode_and_bind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'genre'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-7921fa2015e4>\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(df_input)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mmode_encoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m \u001b[1;34m'Major'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Minor'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'key'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'key'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time_signature'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time_signature'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_sig_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mode'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'df' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# helper function to one hot encode genre\n",
    "def encode_and_bind(original_dataframe, feature_to_encode):\n",
    "    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n",
    "    res = pd.concat([original_dataframe, dummies], axis=1)\n",
    "    return(res)\n",
    "\n",
    "def preprocess(df_input):\n",
    "\n",
    "    time_sig_encoding = { '0/4' : 0, '1/4' : 1, \n",
    "                         '3/4' : 3, '4/4' : 4,\n",
    "                         '5/4' : 5}\n",
    "\n",
    "    key_encoding = { 'A' : 0, 'A#' : 1, 'B' : 2,\n",
    "                    'C' : 3,  'C#' : 4,  'D' : 5,\n",
    "                    'D#' : 6, 'E' : 7, 'F' : 8,\n",
    "                    'F#' : 9, 'G' : 10, 'G#' : 11 }\n",
    "\n",
    "    mode_encoding = { 'Major':0, 'Minor':1}      \n",
    "\n",
    "    df['key'] = df['key'].map(key_encoding)\n",
    "    df['time_signature'] = df['time_signature'].map(time_sig_encoding)\n",
    "    df['mode'] = df['mode'].map(mode_encoding)\n",
    "    df = encode_and_bind(df, 'genre')\n",
    "    \n",
    "df = preprocess(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-dfd2a9b66af3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GHo9s6IAyls2"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'sort_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ddc189d95b1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'popularity'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'sort_values'"
     ]
    }
   ],
   "source": [
    "df.sort_values('popularity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'genre'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-364db003f6c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'genre'"
     ]
    }
   ],
   "source": [
    "df.genre.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zw-EHBcot9td"
   },
   "source": [
    "# MODELING: Nearest Neighbors\n",
    "resources: https://scikit-learn.org/stable/modules/neighbors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hGlvDu8lQfRf"
   },
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "neigh = NearestNeighbors(n_neighbors=11)\n",
    "\n",
    "features = list(df.columns[4:])\n",
    "X = df[features].values\n",
    "# y = df[target]\n",
    "\n",
    "X.shape # y.shape\n",
    "# target = 'track_id'\n",
    "\n",
    "%time\n",
    "neigh.fit(X) # NN doesn't need to fit Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Test on Song Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXgOux8Y1eFF"
   },
   "outputs": [],
   "source": [
    "# highest ranking popularity song from Ariana Grande\n",
    "test_song = X[9027]\n",
    "df.iloc[9027]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zRXHue0N1Ekk"
   },
   "outputs": [],
   "source": [
    "distance, neighbors = neigh.kneighbors(np.array([test_song]))\n",
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DSjA-vST4lVn"
   },
   "outputs": [],
   "source": [
    "neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6q5E6F9d3rI3"
   },
   "outputs": [],
   "source": [
    "song_list = []\n",
    "for idx in neighbors[0][2:]: # this way excludes itself\n",
    "    row = df.iloc[idx]\n",
    "    print(f'Artist: {row.artist_name} - Track: {row.track_name}')\n",
    "    song_list.append((row.artist_name, row.track_name))\n",
    "song_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Function to Return 10 Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function for what was done manually above\n",
    "generalized for other dataframes instead of hard coded therefore:\n",
    "takes in a dataframe, a feature set array, and a song ID\n",
    "and returns a list of tuples of artist name and track names\n",
    "\"\"\"\n",
    "from typing import List, Tuple\n",
    "\n",
    "def closest_ten(df: pd.DataFrame, X_array: np.ndarray ,song_id: int) -> List[Tuple] :\n",
    "    song = df.iloc[song_id]\n",
    "    X_song = X[song_id]\n",
    "    _, neighbors = neigh.kneighbors(np.array([X_song]))\n",
    "    song_list = []\n",
    "    for idx in neighbors[0][2:]: \n",
    "        row = df.iloc[idx]\n",
    "       # print(f'Artist: {row.artist_name} - Track: {row.track_name}')\n",
    "        song_list.append((row.artist_name, row.track_name))\n",
    "    return song_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NXi-FUX6sbWm"
   },
   "outputs": [],
   "source": [
    "# example of function call \n",
    "closest_ten(df, X, 9027)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA -> NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy to transform in case you want to do stuff with the other one later in notebook\n",
    "df_copy = df[features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array, mean, std, cov\n",
    "from numpy.linalg import eig\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = df_copy.mean()\n",
    "# print(\"\\n Means:\", means)\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_X = scaler.fit_transform(df_copy.values)\n",
    "pca = PCA()\n",
    "df_pca = pca.fit(pca_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "pca_neigh = NearestNeighbors(n_neighbors=11)\n",
    "pca_neigh.fit(pca_X) # NN doesn't need to fit Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refactor later if have time\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# pipeline = make_pipeline(\n",
    "#     StandardScaler(),\n",
    "#     NearestNeighbors())\n",
    "\n",
    "# pipeline.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Encoder -> NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 10 # compression of factor 4.1 assuming input of 41"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "38aCXICFoz55"
   },
   "source": [
    "# Export Model with Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4SBVgLGvn8hS"
   },
   "outputs": [],
   "source": [
    "filename = 'NearestNeighborGenres.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kLfmVJiKoN8X"
   },
   "outputs": [],
   "source": [
    "joblib.dump(neigh, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_filename = 'PCANearestNeighborGenres.sav'\n",
    "joblib.dump(pca_neigh, pca_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VD4hvXIVwyRG"
   },
   "outputs": [],
   "source": [
    "# one hot encoding, rolled back\n",
    "# def encode_and_bind(original_dataframe, feature_to_encode):\n",
    "#     dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n",
    "#     res = pd.concat([original_dataframe, dummies], axis=1)\n",
    "#     return(res)\n",
    "\n",
    "# df = encode_and_bind(df, 'key')\n",
    "# df = encode_and_bind(df, 'mode')\n",
    "# df = encode_and_bind(df, 'time_signature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Model with Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d0G2dBalpjTx"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model = neigh\n",
    "\n",
    "filename = 'filename.pkl'\n",
    "\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "#then send this pkl file to DE team\n",
    "\n",
    "#DE team:\n",
    "#Make sure to save the pkl file in the same folder as the app\n",
    "\n",
    "#To read it into the app:\n",
    "\n",
    "# with open(filename, 'rb') as f:\n",
    "#     model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Spotify_Model.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "U4-S2-NN",
   "language": "python",
   "name": "u4-s2-nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
