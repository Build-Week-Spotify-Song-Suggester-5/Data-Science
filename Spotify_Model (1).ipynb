{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spotify_Model.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kgdLqZi5sa4A"
      },
      "source": [
        "# Imports and Installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IzCZwfItsOVX",
        "colab": {}
      },
      "source": [
        "# install latest version of polyglot language detection library for stretch\n",
        "!pip install -U git+https://github.com/aboSamoor/polyglot.git@master"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e2BCdkR4U5SR",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import pandas_profiling \n",
        "from sklearn import preprocessing # for category encoder\n",
        "from polyglot.detect import Detector # for language detection stretch\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.model_selection import train_test_split\n",
        "# much more efficient for larger files like Nearest Neighbors which the model\n",
        "import joblib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RA1kLoqhsemw"
      },
      "source": [
        "# EDA & PROFILE REPORT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mGRbNKAzU-sp",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/aguilargallardo/DS-Unit-2-Applied-Modeling/master/data/SpotifyFeatures.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B5D76wyCU8l3",
        "colab": {}
      },
      "source": [
        "pandas_profiling.ProfileReport(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7NnGXkWYs3-0"
      },
      "source": [
        "# Data Engineering Language Detection (Stretch, not working yet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZPBCYrRgj0GC",
        "colab": {}
      },
      "source": [
        "# test of polyglot detector\n",
        "\n",
        "arabic_text = u\"\"\"\n",
        "أفاد مصدر امني في قيادة عمليات صلاح الدين في العراق بأن \" القوات الامنية تتوقف لليوم\n",
        "الثالث على التوالي عن التقدم الى داخل مدينة تكريت بسبب\n",
        "انتشار قناصي التنظيم الذي يطلق على نفسه اسم \"الدولة الاسلامية\" والعبوات الناسفة\n",
        "والمنازل المفخخة والانتحاريين، فضلا عن ان القوات الامنية تنتظر وصول تعزيزات اضافية \".\n",
        "\"\"\"\n",
        "\n",
        "detector = Detector(arabic_text)\n",
        "print(detector.language)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gmz9VpoQkf4i",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "   TODO: figure out UTF-8 ERROR or just do try catch exception and return \n",
        "   unknown or something\n",
        "   below code does not work\n",
        "\"\"\"\n",
        "\n",
        "# df.track_name = df.track_name.astype(str)\n",
        "# df['poly_obj'] = df.track_name.apply(lambda x: Detector(x, quiet=True))\n",
        "# df['Track-lang'] = df['poly_obj'].apply(lambda x: icu.Locale.getDisplayName(x.language.locale))\n",
        "# df['Track-LangConfidence'] = df['poly_obj'].apply( lambda x: x.language.confidence)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l3YOD4aFtUfj"
      },
      "source": [
        "# DATA ENGINEERING CATEGORY ENCODING OF OBJECT FEATURES\n",
        "note: might need to create another column of encoded languages\n",
        "resources below: https://chrisalbon.com/machine_learning/preprocessing_structured_data/convert_pandas_categorical_column_into_integers_for_scikit-learn/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD4hvXIVwyRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_and_bind(original_dataframe, feature_to_encode):\n",
        "    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n",
        "    res = pd.concat([original_dataframe, dummies], axis=1)\n",
        "    return(res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pHCnkNj0PHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = encode_and_bind(df, 'key')\n",
        "df = encode_and_bind(df, 'mode')\n",
        "df = encode_and_bind(df, 'time_signature')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2VusgmXCqSyp",
        "colab": {}
      },
      "source": [
        "# check worked out\n",
        "df.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zw-EHBcot9td"
      },
      "source": [
        "# MODELING: Nearest Neighbors\n",
        "resources: https://scikit-learn.org/stable/modules/neighbors.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KE5ePbh_KCxb",
        "colab": {}
      },
      "source": [
        "neigh = NearestNeighbors()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hGlvDu8lQfRf",
        "colab": {}
      },
      "source": [
        "# to remove the transformed columns from model \n",
        "remove = ['key', 'mode','time_signature']\n",
        "features = [i for i in list(df.columns[4:]) if i not in remove]\n",
        "# target = 'track_id'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dsJSuEj6Q1eT",
        "colab": {}
      },
      "source": [
        "X = df[features]\n",
        "# y = df[target]\n",
        "\n",
        "X.shape, #y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D4kA2zQmORy3",
        "colab": {}
      },
      "source": [
        "neigh.fit(X) # NN doesn't need to fit Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Clkrrf3CT3Xb",
        "colab_type": "text"
      },
      "source": [
        "#### Nicole's Imported Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAeGBkjVlZxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# K nearest neighbors NN https://www.reddit.com/r/MachineLearning/comments/2f8jff/using_neural_networks_for_nearest_neighbor/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqoPylx_T6co",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rom knn_from_scratch import knn, euclidean_distance\n",
        "\n",
        "def recommend_songs(movie_query, k_recommendations):\n",
        "    raw_movies_data = []\n",
        "    with open('movies_recommendation_data.csv', 'r') as md:\n",
        "        # Discard the first line (headings)\n",
        "        next(md)\n",
        "\n",
        "        # Read the data into memory\n",
        "        for line in md.readlines():\n",
        "            data_row = line.strip().split(',')\n",
        "            raw_movies_data.append(data_row)\n",
        "\n",
        "    # Prepare the data for use in the knn algorithm by picking\n",
        "    # the relevant columns and converting the numeric columns\n",
        "    # to numbers since they were read in as strings\n",
        "    songs_recommendation_data = []\n",
        "    for row in raw_movies_data:\n",
        "        data_row = list(map(float, row[2:]))\n",
        "        songs_recommendation_data.append(data_row)\n",
        "\n",
        "    # Use the KNN algorithm to get the 5 movies that are most\n",
        "    # similar to The Post.\n",
        "    recommendation_indices, _ = knn(\n",
        "        movies_recommendation_data, movie_query, k=k_recommendations,\n",
        "        distance_fn=euclidean_distance, choice_fn=lambda x: None\n",
        "    )\n",
        "\n",
        "    movie_recommendations = []\n",
        "    for _, index in recommendation_indices:\n",
        "        movie_recommendations.append(raw_movies_data[index])\n",
        "\n",
        "    return movie_recommendations\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    the_post = [7.2, 1, 1, 0, 0, 0, 0, 1, 0] # feature vector for The Post\n",
        "    recommended_movies = recommend_movies(movie_query=the_post, k_recommendations=5)\n",
        "\n",
        "    # Print recommended song titles\n",
        "    for recommendation in recommended_songs:\n",
        "        print(recommendation[10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38aCXICFoz55",
        "colab_type": "text"
      },
      "source": [
        "# Export Model with Joblib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SBVgLGvn8hS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'NearestNeighbor.sav'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLfmVJiKoN8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "joblib.dump(neigh, filename)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}