{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cluster_Mapping_Exploration.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "38aCXICFoz55"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx2fy51HkPyI",
        "colab_type": "text"
      },
      "source": [
        "## Exploring Clusers in Data\n",
        "\n",
        "- Use an auto-encoder to reduce dimensions down to 2 and made a scatter plot and then used kmeans clustering to colormap the clusters\n",
        "- use pca or tsne for that, but autoencoder I think can accomplish that task as well, if ur output later has 2 neurons, rt?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kgdLqZi5sa4A"
      },
      "source": [
        "# Imports and Installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI_0n7zzumGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import pandas_profiling \n",
        "from sklearn import preprocessing # for category encoder\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.model_selection import train_test_split\n",
        "# much more efficient for larger files like Nearest Neighbors which the model\n",
        "import joblib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuXor5ics6t4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in data\n",
        "ddf = pd.read_csv('https://raw.githubusercontent.com/Build-Week-Spotify-Song-Suggester-5/Data-Science/master/spotify_unique_track_id.csv')\n",
        "\n",
        "\n",
        "df = df.dropna() # drop null values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0waFzIOxi99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnJsmHPSs1EM",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network\n",
        "\n",
        "#### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvw155X9swUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_sig_encoding = { '0/4' : 0, '1/4' : 1, \n",
        "                     '3/4' : 3, '4/4' : 4,\n",
        "                     '5/4' : 5}\n",
        "\n",
        "key_encoding = { 'A' : 0, 'A#' : 1, 'B' : 2,\n",
        "                'C' : 3,  'C#' : 4,  'D' : 5,\n",
        "                'D#' : 6, 'E' : 7, 'F' : 8,\n",
        "                'F#' : 9, 'G' : 10, ' G#' : 11 }\n",
        "\n",
        "mode_encoding = { 'Major':0, 'Minor':1}      \n",
        "\n",
        "df['key'] = df['key'].map(key_encoding)\n",
        "df['time_signature'] = df['time_signature'].map(time_sig_encoding)\n",
        "df['mode'] = df['mode'].map(mode_encoding)\n",
        "\n",
        "# helper function to one hot encode genre\n",
        "\n",
        "def encode_and_bind(original_dataframe, feature_to_encode):\n",
        "    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n",
        "    res = pd.concat([original_dataframe, dummies], axis=1)\n",
        "    return(res)\n",
        "\n",
        "df = encode_and_bind(df, 'genre')\n",
        "\n",
        "df = df.dropna() # drop null values again not sure why it created null values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2VusgmXCqSyp",
        "colab": {}
      },
      "source": [
        "# check worked out\n",
        "df.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXHnn1tmp36O",
        "colab_type": "text"
      },
      "source": [
        "### Principle Compoonent Analysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN7-7lg0qGyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make copy to transform in case you want to do stuff with the other one later in notebook\n",
        "df_copy = df[features].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4x_lbtQqJG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import array, mean, std, cov\n",
        "from numpy.linalg import eig\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5XtBVbMqNlq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "means = df_copy.mean()\n",
        "# print(\"\\n Means:\", means)\n",
        "scaler = StandardScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM_p1rFQp8rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca_X = scaler.fit_transform(df_copy.values)\n",
        "pca = PCA()\n",
        "df_pca = pca.fit(pca_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtrzYMpQqVHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(pca.explained_variance_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mVZ2-NdqZAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%time\n",
        "pca_neigh = NearestNeighbors(n_neighbors=11)\n",
        "pca_neigh.fit(pca_X) # NN doesn't need to fit Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ChYSLt-vT_03"
      },
      "source": [
        "# MODELING: Nearest Neighbors\n",
        "resources: https://scikit-learn.org/stable/modules/neighbors.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q4LqcfPcT-_y",
        "colab": {}
      },
      "source": [
        "neigh = NearestNeighbors()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GFtCGrpLT-j9",
        "colab": {}
      },
      "source": [
        "# to remove the transformed columns from model \n",
        "remove = ['key', 'mode','time_signature']\n",
        "features = [i for i in list(df.columns[4:]) if i not in remove]\n",
        "# target = 'track_id'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dsJSuEj6Q1eT",
        "colab": {}
      },
      "source": [
        "X = df[features]\n",
        "# y = df[target]\n",
        "\n",
        "X.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D4kA2zQmORy3",
        "colab": {}
      },
      "source": [
        "neigh.fit(X) # NN doesn't need to fit Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftWHNeP3T4M3",
        "colab_type": "text"
      },
      "source": [
        "### Vectorize Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNSNGvqAy-O0",
        "colab_type": "text"
      },
      "source": [
        "### Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38aCXICFoz55",
        "colab_type": "text"
      },
      "source": [
        "# Export Model with Joblib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SBVgLGvn8hS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'NearestNeighbor.sav'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLfmVJiKoN8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "joblib.dump(neigh, filename)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}